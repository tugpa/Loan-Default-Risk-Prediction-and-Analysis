{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d297c574",
   "metadata": {},
   "source": [
    "<h2> Predictive Modelling </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "39980970",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "669a48ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['term', 'grade', 'sub_grade', 'employment_length', 'home_ownership', 'verification_status', 'issue_date', 'payment_plan', 'purpose', 'earliest_credit_line', 'application_type']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('loan_payments_versions/loan_payments_transformed.csv')\n",
    "df = df.drop(['id', 'member_id'], axis=1)\n",
    "\n",
    "good_loan_statuses = [\n",
    "    \"Fully Paid\",\n",
    "    \"Does not meet the credit policy. Status:Fully Paid\",\n",
    "]\n",
    "bad_loan_statuses = [\n",
    "    \"Charged Off\",\n",
    "    \"Does not meet the credit policy. Status:Charged Off\",\n",
    "]\n",
    "\n",
    "historical_df = df[\n",
    "    df[\"loan_status\"].isin(good_loan_statuses + bad_loan_statuses)\n",
    "].copy()\n",
    "historical_df[\"loan_status\"] = historical_df[\"loan_status\"].apply(\n",
    "    lambda x: 1 if x in good_loan_statuses else 0\n",
    ")\n",
    "leaky_columns = [\n",
    "    'last_payment_date',\n",
    "    'last_payment_amount',\n",
    "    'last_credit_pull_date',\n",
    "    'recoveries',\n",
    "    'collection_recovery_fee',\n",
    "    'total_payment',\n",
    "    'total_rec_prncp',\n",
    "    'total_rec_int',\n",
    "    'total_rec_late_fee',\n",
    "]\n",
    "\n",
    "historical_df = historical_df.drop(columns=leaky_columns)\n",
    "categorical_cols = historical_df.select_dtypes(include='object').columns.tolist()\n",
    "print(categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "707125db",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_df_encoded = pd.get_dummies(historical_df,columns=categorical_cols, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eb8e159e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components that explain at least 95% of variance: 633\n"
     ]
    }
   ],
   "source": [
    "X = historical_df_encoded.drop('loan_status', axis=1)\n",
    "Y = historical_df_encoded['loan_status']\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "pca = PCA()\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "explained_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "n_components = np.argmax(explained_variance >= 0.95) + 1\n",
    "\n",
    "print(f\"Number of components that explain at least 95% of variance: {n_components}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "57b60afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training and Evaluating Logistic Regression ---\n",
      "\n",
      "Accuracy Score: 0.8846\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 619 1066]\n",
      " [  72 8101]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.37      0.52      1685\n",
      "           1       0.88      0.99      0.93      8173\n",
      "\n",
      "    accuracy                           0.88      9858\n",
      "   macro avg       0.89      0.68      0.73      9858\n",
      "weighted avg       0.89      0.88      0.86      9858\n",
      "\n",
      "====================================================\n",
      "\n",
      "--- Training and Evaluating Random Forest ---\n",
      "\n",
      "Accuracy Score: 0.8284\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  29 1656]\n",
      " [  36 8137]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.02      0.03      1685\n",
      "           1       0.83      1.00      0.91      8173\n",
      "\n",
      "    accuracy                           0.83      9858\n",
      "   macro avg       0.64      0.51      0.47      9858\n",
      "weighted avg       0.77      0.83      0.76      9858\n",
      "\n",
      "====================================================\n",
      "\n",
      "--- Training and Evaluating LightGBM ---\n",
      "[LightGBM] [Info] Number of positive: 19071, number of negative: 3931\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050990 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 161415\n",
      "[LightGBM] [Info] Number of data points in the train set: 23002, number of used features: 633\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.829102 -> initscore=1.579275\n",
      "[LightGBM] [Info] Start training from score 1.579275\n",
      "\n",
      "Accuracy Score: 0.8341\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 115 1570]\n",
      " [  65 8108]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.07      0.12      1685\n",
      "           1       0.84      0.99      0.91      8173\n",
      "\n",
      "    accuracy                           0.83      9858\n",
      "   macro avg       0.74      0.53      0.52      9858\n",
      "weighted avg       0.80      0.83      0.77      9858\n",
      "\n",
      "====================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=n_components)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, Y, test_size=0.3, random_state=42, stratify=Y)\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=300, random_state=42, n_jobs=-1),\n",
    "    \"LightGBM\": LGBMClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"--- Training and Evaluating {name} ---\")\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    print(f\"\\nAccuracy Score: {accuracy_score(y_test, predictions):.4f}\")\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, predictions))\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, predictions))\n",
    "    print(\"====================================================\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6b53b77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training and Evaluating Logistic Regression (Balanced) ---\n",
      "\n",
      "Accuracy Score: 0.8842\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1349  336]\n",
      " [ 806 7367]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.80      0.70      1685\n",
      "           1       0.96      0.90      0.93      8173\n",
      "\n",
      "    accuracy                           0.88      9858\n",
      "   macro avg       0.79      0.85      0.82      9858\n",
      "weighted avg       0.90      0.88      0.89      9858\n",
      "\n",
      "====================================================\n",
      "\n",
      "--- Training and Evaluating Random Forest (Balanced) ---\n",
      "\n",
      "Accuracy Score: 0.8295\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  12 1673]\n",
      " [   8 8165]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.01      0.01      1685\n",
      "           1       0.83      1.00      0.91      8173\n",
      "\n",
      "    accuracy                           0.83      9858\n",
      "   macro avg       0.71      0.50      0.46      9858\n",
      "weighted avg       0.79      0.83      0.75      9858\n",
      "\n",
      "====================================================\n",
      "\n",
      "--- Training and Evaluating LightGBM (Balanced) ---\n",
      "[LightGBM] [Info] Number of positive: 19071, number of negative: 3931\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050765 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 161415\n",
      "[LightGBM] [Info] Number of data points in the train set: 23002, number of used features: 633\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "\n",
      "Accuracy Score: 0.7382\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 896  789]\n",
      " [1792 6381]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.53      0.41      1685\n",
      "           1       0.89      0.78      0.83      8173\n",
      "\n",
      "    accuracy                           0.74      9858\n",
      "   macro avg       0.61      0.66      0.62      9858\n",
      "weighted avg       0.79      0.74      0.76      9858\n",
      "\n",
      "====================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Addressing Class Imbalance because of which the models have a very low recall score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, Y, test_size=0.3, random_state=42, stratify=Y)\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced'),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1, class_weight='balanced'),\n",
    "    \"LightGBM\": LGBMClassifier(random_state=42, class_weight='balanced')\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"--- Training and Evaluating {name} (Balanced) ---\")\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    print(f\"\\nAccuracy Score: {accuracy_score(y_test, predictions):.4f}\")\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, predictions))\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, predictions))\n",
    "    print(\"====================================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "01de5f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train before SMOTE: (23002, 633)\n",
      "Shape of X_train after SMOTE: (38142, 633)\n",
      "\n",
      "--- Training and Evaluating Logistic Regression (with SMOTE) ---\n",
      "\n",
      "Accuracy Score: 0.9066\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1337  348]\n",
      " [ 573 7600]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.79      0.74      1685\n",
      "           1       0.96      0.93      0.94      8173\n",
      "\n",
      "    accuracy                           0.91      9858\n",
      "   macro avg       0.83      0.86      0.84      9858\n",
      "weighted avg       0.91      0.91      0.91      9858\n",
      "\n",
      "====================================================\n",
      "\n",
      "\n",
      "--- Training and Evaluating Random Forest (with SMOTE) ---\n",
      "\n",
      "Accuracy Score: 0.8039\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 225 1460]\n",
      " [ 473 7700]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.13      0.19      1685\n",
      "           1       0.84      0.94      0.89      8173\n",
      "\n",
      "    accuracy                           0.80      9858\n",
      "   macro avg       0.58      0.54      0.54      9858\n",
      "weighted avg       0.75      0.80      0.77      9858\n",
      "\n",
      "====================================================\n",
      "\n",
      "\n",
      "--- Training and Evaluating LightGBM (with SMOTE) ---\n",
      "[LightGBM] [Info] Number of positive: 19071, number of negative: 19071\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.076574 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 161415\n",
      "[LightGBM] [Info] Number of data points in the train set: 38142, number of used features: 633\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "\n",
      "Accuracy Score: 0.7697\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 656 1029]\n",
      " [1241 6932]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.39      0.37      1685\n",
      "           1       0.87      0.85      0.86      8173\n",
      "\n",
      "    accuracy                           0.77      9858\n",
      "   macro avg       0.61      0.62      0.61      9858\n",
      "weighted avg       0.78      0.77      0.78      9858\n",
      "\n",
      "====================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, Y, test_size=0.3, random_state=42, stratify=Y)\n",
    "\n",
    "# --- Applying SMOTE ---\n",
    "print(\"Shape of X_train before SMOTE:\", X_train.shape)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "print(\"Shape of X_train after SMOTE:\", X_train_smote.shape)\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    \"LightGBM\": LGBMClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n--- Training and Evaluating {name} (with SMOTE) ---\")\n",
    "    # Train on the SMOTE-resampled training data\n",
    "    model.fit(X_train_smote, y_train_smote)\n",
    "    \n",
    "    # Evaluate on the original, untouched test data\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    print(f\"\\nAccuracy Score: {accuracy_score(y_test, predictions):.4f}\")\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, predictions))\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, predictions))\n",
    "    print(\"====================================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4342d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tuning Logistic Regression (ElasticNet) ---\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters for Logistic Regression (ElasticNet): {'C': 10, 'l1_ratio': 0.25, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga'}\n",
      "\n",
      "Results for Tuned Logistic Regression (ElasticNet):\n",
      "Accuracy Score: 0.7505\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.69      0.49      1685\n",
      "           1       0.92      0.76      0.84      8173\n",
      "\n",
      "    accuracy                           0.75      9858\n",
      "   macro avg       0.65      0.73      0.66      9858\n",
      "weighted avg       0.83      0.75      0.78      9858\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "\n",
      "--- Tuning Random Forest ---\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "\n",
      "Best Parameters for Random Forest: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "\n",
      "Results for Tuned Random Forest:\n",
      "Accuracy Score: 0.8091\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.13      0.18      1685\n",
      "           1       0.84      0.95      0.89      8173\n",
      "\n",
      "    accuracy                           0.81      9858\n",
      "   macro avg       0.59      0.54      0.54      9858\n",
      "weighted avg       0.76      0.81      0.77      9858\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "\n",
      "--- Tuning LightGBM ---\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "[LightGBM] [Info] Number of positive: 19071, number of negative: 19071\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070926 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 161415\n",
      "[LightGBM] [Info] Number of data points in the train set: 38142, number of used features: 633\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "\n",
      "Best Parameters for LightGBM: {'learning_rate': 0.1, 'n_estimators': 200, 'num_leaves': 50}\n",
      "\n",
      "Results for Tuned LightGBM:\n",
      "Accuracy Score: 0.8110\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.29      0.34      1685\n",
      "           1       0.86      0.92      0.89      8173\n",
      "\n",
      "    accuracy                           0.81      9858\n",
      "   macro avg       0.64      0.60      0.62      9858\n",
      "weighted avg       0.79      0.81      0.80      9858\n",
      "\n",
      "----------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameter grids for each model\n",
    "param_grid_lr = {\n",
    "    'penalty': ['elasticnet'],\n",
    "    'C': [0.1, 1, 10],\n",
    "    'l1_ratio': [0.25, 0.5, 0.75],\n",
    "    'solver': ['saga'],\n",
    "    'max_iter': [2000]\n",
    "}\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "param_grid_lgbm = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'num_leaves': [31, 50]\n",
    "}\n",
    "\n",
    "# Models and grids to iterate over\n",
    "tuned_models = {\n",
    "    \"Logistic Regression (ElasticNet)\": (LogisticRegression(random_state=42), param_grid_lr),\n",
    "    \"Random Forest\": (RandomForestClassifier(random_state=42, n_jobs=-1), param_grid_rf),\n",
    "    \"LightGBM\": (LGBMClassifier(random_state=42), param_grid_lgbm)\n",
    "}\n",
    "\n",
    "for name, (model, params) in tuned_models.items():\n",
    "    print(f\"\\n--- Tuning {name} ---\")\n",
    "    # Using F1 score for the minority class (0) as the scoring metric\n",
    "    grid_search = GridSearchCV(model, params, cv=3, scoring='f1', n_jobs=-1, verbose=1)\n",
    "    grid_search.fit(X_train_smote, y_train_smote)\n",
    "    \n",
    "    print(f\"\\nBest Parameters for {name}: {grid_search.best_params_}\")\n",
    "    \n",
    "    best_model = grid_search.best_estimator_\n",
    "    predictions = best_model.predict(X_test)\n",
    "    \n",
    "    print(f\"\\nResults for Tuned {name}:\")\n",
    "    print(f\"Accuracy Score: {accuracy_score(y_test, predictions):.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, predictions))\n",
    "    print(\"----------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eaf59954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tuning Logistic Regression (ElasticNet) ---\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters for Logistic Regression (ElasticNet): {'C': 10, 'l1_ratio': 0.75, 'max_iter': 5000, 'penalty': 'elasticnet', 'solver': 'saga'}\n",
      "\n",
      "Results for Tuned Logistic Regression (ElasticNet):\n",
      "Accuracy Score: 0.8322\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.75      0.60      1685\n",
      "           1       0.94      0.85      0.89      8173\n",
      "\n",
      "    accuracy                           0.83      9858\n",
      "   macro avg       0.72      0.80      0.75      9858\n",
      "weighted avg       0.87      0.83      0.84      9858\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "\n",
      "--- Tuning Random Forest ---\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "\n",
      "Best Parameters for Random Forest: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "\n",
      "Results for Tuned Random Forest:\n",
      "Accuracy Score: 0.8091\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.13      0.18      1685\n",
      "           1       0.84      0.95      0.89      8173\n",
      "\n",
      "    accuracy                           0.81      9858\n",
      "   macro avg       0.59      0.54      0.54      9858\n",
      "weighted avg       0.76      0.81      0.77      9858\n",
      "\n",
      "----------------------------------------------------\n",
      "\n",
      "\n",
      "--- Tuning LightGBM ---\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "[LightGBM] [Info] Number of positive: 19071, number of negative: 19071\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.077533 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 161415\n",
      "[LightGBM] [Info] Number of data points in the train set: 38142, number of used features: 633\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "\n",
      "Best Parameters for LightGBM: {'learning_rate': 0.1, 'n_estimators': 200, 'num_leaves': 50}\n",
      "\n",
      "Results for Tuned LightGBM:\n",
      "Accuracy Score: 0.8110\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.29      0.34      1685\n",
      "           1       0.86      0.92      0.89      8173\n",
      "\n",
      "    accuracy                           0.81      9858\n",
      "   macro avg       0.64      0.60      0.62      9858\n",
      "weighted avg       0.79      0.81      0.80      9858\n",
      "\n",
      "----------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameter grids for each model\n",
    "param_grid_lr = {\n",
    "    'penalty': ['elasticnet'],\n",
    "    'C': [0.1, 1, 10],\n",
    "    'l1_ratio': [0.25, 0.5, 0.75],\n",
    "    'solver': ['saga'],\n",
    "    'max_iter': [5000]\n",
    "}\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "param_grid_lgbm = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'num_leaves': [31, 50]\n",
    "}\n",
    "\n",
    "# Models and grids to iterate over\n",
    "tuned_models = {\n",
    "    \"Logistic Regression (ElasticNet)\": (LogisticRegression(random_state=42), param_grid_lr),\n",
    "    \"Random Forest\": (RandomForestClassifier(random_state=42, n_jobs=-1), param_grid_rf),\n",
    "    \"LightGBM\": (LGBMClassifier(random_state=42), param_grid_lgbm)\n",
    "}\n",
    "\n",
    "for name, (model, params) in tuned_models.items():\n",
    "    print(f\"\\n--- Tuning {name} ---\")\n",
    "    # Using F1 score for the minority class (0) as the scoring metric\n",
    "    grid_search = GridSearchCV(model, params, cv=3, scoring='f1_macro', n_jobs=-1, verbose=1)\n",
    "    grid_search.fit(X_train_smote, y_train_smote)\n",
    "    \n",
    "    print(f\"\\nBest Parameters for {name}: {grid_search.best_params_}\")\n",
    "    \n",
    "    best_model = grid_search.best_estimator_\n",
    "    predictions = best_model.predict(X_test)\n",
    "    \n",
    "    print(f\"\\nResults for Tuned {name}:\")\n",
    "    print(f\"Accuracy Score: {accuracy_score(y_test, predictions):.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, predictions))\n",
    "    print(\"----------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f8acb741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Process finished. All results saved to 'model_evaluation_results.txt'\n"
     ]
    }
   ],
   "source": [
    "class Logger(object):\n",
    "    def __init__(self, filename=\"model_evaluation_results.txt\"):\n",
    "        self.terminal = sys.stdout\n",
    "        self.log = open(filename, \"w\")\n",
    "\n",
    "    def write(self, message):\n",
    "        self.terminal.write(message)\n",
    "        self.log.write(message)\n",
    "\n",
    "    def flush(self):\n",
    "        self.terminal.flush()\n",
    "        self.log.flush()\n",
    "\n",
    "sys.stdout = Logger()\n",
    "sys.stdout.log.close()\n",
    "sys.stdout = sys.stdout.terminal\n",
    "print(\"\\nProcess finished. All results saved to 'model_evaluation_results.txt'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
